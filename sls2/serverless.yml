service: kizawa-sample

frameworkVersion: "2"
# useDotenv: false

plugins:
  - serverless-offline
  - serverless-s3-local
  - serverless-deployment-bucket
  - serverless-apigw-binary
  - serverless-s3-remover
  - serverless-plugin-aws-alerts
  # - serverless-dotenv-plugin

provider:
  name: aws
  runtime: python3.8
  stage: dev
  region: ap-northeast-1
  profile: ccti-dev
  environment:
    DEPLOYMENT_BUCKET_NAME: ${self:service}-${opt:stage, self:provider.stage}-deployment-bucket
    RECORDS_BUCKET_NAME1: ${self:service}-${opt:stage, self:provider.stage}-records-bucket1
    RECORDS_BUCKET_NAME2: ${self:service}-${opt:stage, self:provider.stage}-records-bucket2
    TRANSCRIBE_BUCKET_NAME: ${self:service}-${opt:stage, self:provider.stage}-transcribe-bucket
    COMPREHEND_BUCKET_NAME: ${self:service}-${opt:stage, self:provider.stage}-comprehend-bucket
  deploymentBucket:
    name: ${self:provider.environment.DEPLOYMENT_BUCKET_NAME}
  apiGateway:
    shouldStartNameWithService: true
  lambdaHashingVersion: 20201221
  logRetentionInDays: 30
  logs:
    restApi:
      accessLogging: false
      executionLogging: true
      level: ERROR
      fullExecutionData: false
  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:GetObject
        - s3:PutObject
      Resource:
        - "arn:aws:s3:::${self:provider.environment.RECORDS_BUCKET_NAME1}/*"
        - "arn:aws:s3:::${self:provider.environment.RECORDS_BUCKET_NAME2}/*"
        - "arn:aws:s3:::${self:provider.environment.TRANSCRIBE_BUCKET_NAME}/*"
        - "arn:aws:s3:::${self:provider.environment.COMPREHEND_BUCKET_NAME}/*"
    - Effect: Allow
      Action:
        - transcribe:StartTranscriptionJob
      Resource: "*"
    - Effect: Allow
      Action:
        - logs:CreateLogGroup
        - logs:CreateLogStream
        - logs:PutLogEvents
      Resource:
        - "*"
    - Effect: Allow
      Action:
        - "comprehend:*"
      Resource:
        - "*"
  # s3:
  #   port: 4569
  #   directory: sample
custom:
  apigwBinary:
    types:
      - "*/*"
  remover:
    buckets:
      - ${self:provider.environment.DEPLOYMENT_BUCKET_NAME}
      - ${self:provider.environment.RECORDS_BUCKET_NAME1}
      - ${self:provider.environment.RECORDS_BUCKET_NAME2}
      - ${self:provider.environment.TRANSCRIBE_BUCKET_NAME}
      - ${self:provider.environment.COMPREHEND_BUCKET_NAME}

  alerts:
    stages:
      - dev
    topics:
      alarm:
        topic: ${self:service}-${opt:stage, self:provider.stage}-alerts-alarm
        notifications:
          - protocol: email
            endpoint: kizawa_shota@comsq.com
    alarms:
      - functionErrors
      - functionThrottles

  # alerts:
  #   stages:
  #     - dev
  #   dashboards: true
  #   nameTemplate: ${self:service}-$[metricName]-Alarm
  #   prefixTemplate: ${self:service}
  #   topics:
  #     # ok: ${self:service}-${opt:stage}-alerts-ok
  #     alarm: ${self:service}-${opt:stage}-alerts-alarm
  #     insufficientData: ${self:service}-${opt:stage}-alerts-insufficientData
  #   definitions:
  #     functionErrors:
  #       period: 300
  #     customAlarm:
  #       actionsEnabled: false
  #       description: "My custom alarm"
  #       namespace: "AWS/Lambda"
  #       nameTemplate: $[functionName]-Duration-IMPORTANT-Alarm
  #       prefixTemplate: $[stackName]
  #       metric: duration
  #       threshold: 200
  #       statistic: Average
  #       period: 300
  #       evaluationPeriods: 1
  #       datapointsToAlarm: 1
  #       comparisonOperator: GreaterThanOrEqualToThreshold
  #   alarms:
  #     - functionThrottles
  #     - functionErrors
  #     - functionInvocations
  #     - functionDuration
  # notifications:
  #   - protocol: email
  #     endpoint: ${env:NOTIFICATION_EMAIL}
  # alerts:
  #   stages: # Optionally - select which stages to deploy alarms to
  #     - production
  #     - staging
  #   dashboards: true
  #   topics:
  #     ok:
  #       topic: ${self:service}-${opt:stage}-alerts-ok
  #       notifications: ${self:custom.notifications}
  #     alarm:
  #       topic: ${self:service}-${opt:stage}-alerts-alarm
  #       notifications: ${self:custom.notifications}
  #     insufficientData:
  #       topic: ${self:service}-${opt:stage}-alerts-insufficientData
  #       notifications: ${self:custom.notifications}
  #   definitions:  # these defaults are merged with your definitions
  #     functionErrors:
  #       period: 600
  #     functionInvocations:
  #       threshold: 10
  #       period: 600
  #     customAlarm:
  #       description: 'My custom alarm'
  #       namespace: 'AWS/Lambda'
  #       metric: duration
  #       threshold: 200
  #       statistic: Average
  #       period: 300
  #       evaluationPeriods: 1
  #       datapointsToAlarm: 1
  #       comparisonOperator: GreaterThanThreshold
  #   global:
  #     - functionThrottles
  #     - functionErrors
  #   function:
  #     - functionInvocations
  #     - functionDuration

package:
  exclude:
    - buckets
    - sample
    - __pycache__
    - "*.sh"
    - .gitignore
    - lambda_alarm.yaml

functions:
  transcribe1:
    handler: transcribe.lambda_handler
    events:
      - s3:
          bucket: ${self:provider.environment.RECORDS_BUCKET_NAME1}
          event: s3:ObjectCreated:*
          existing: true
    # alarms:
    #   - customAlarm
    #   - name: fooAlarm
    #     namespace: "AWS/Lambda"
    #     actionsEnabled: false
    #     metric: errors
    #     threshold: 1
    #     statistic: Minimum
    #     period: 60
    #     evaluationPeriods: 1
    #     datapointsToAlarm: 1
    #     comparisonOperator: GreaterThanOrEqualToThreshold
  transcribe2:
    handler: transcribe.lambda_handler
    events:
      - s3:
          bucket: ${self:provider.environment.RECORDS_BUCKET_NAME2}
          event: s3:ObjectCreated:*
          existing: true
    # alarms:
    #   - customAlarm
    #   - name: fooAlarm
    #     namespace: "AWS/Lambda"
    #     actionsEnabled: false
    #     metric: errors
    #     threshold: 1
    #     statistic: Minimum
    #     period: 60
    #     evaluationPeriods: 1
    #     datapointsToAlarm: 1
    #     comparisonOperator: GreaterThanOrEqualToThreshold
  comprehend:
    handler: comprehend.lambda_handler
    events:
      - s3:
          bucket: ${self:provider.environment.TRANSCRIBE_BUCKET_NAME}
          event: s3:ObjectCreated:*
          rules:
            - suffix: -transcribe.json
    # alarms:
    #   - customAlarm
    #   - name: fooAlarm
    #     namespace: "AWS/Lambda"
    #     actionsEnabled: false
    #     metric: errors
    #     threshold: 1
    #     statistic: Minimum
    #     period: 60
    #     evaluationPeriods: 1
    #     datapointsToAlarm: 1
    #     comparisonOperator: GreaterThanOrEqualToThreshold
  results:
    handler: test_results.get
    events:
      - http:
          path: /results/{records_bucket}/{proxy+}
          method: get
    # alarms:
    #   - customAlarm
    #   - name: fooAlarm
    #     namespace: "AWS/Lambda"
    #     actionsEnabled: false
    #     metric: errors
    #     threshold: 1
    #     statistic: Minimum
    #     period: 60
    #     evaluationPeriods: 1
    #     datapointsToAlarm: 1
    #     comparisonOperator: GreaterThanOrEqualToThreshold
  records_get:
    handler: test_records.get
    events:
      - http:
          path: records/{records_bucket}/{proxy+}
          method: get
    # alarms:
    #   - customAlarm
    #   - name: fooAlarm
    #     namespace: "AWS/Lambda"
    #     actionsEnabled: false
    #     metric: errors
    #     threshold: 1
    #     statistic: Minimum
    #     period: 60
    #     evaluationPeriods: 1
    #     datapointsToAlarm: 1
    #     comparisonOperator: GreaterThanOrEqualToThreshold
  # records_post:
  #   handler: test_records.post
  #   events:
  #     - http:
  #         path: records
  #         method: post

resources:
  Resources:
    S3AudioBucket1:
      Type: "AWS::S3::Bucket"
      Properties:
        BucketName: ${self:provider.environment.RECORDS_BUCKET_NAME1}
    S3AudioBucket2:
      Type: "AWS::S3::Bucket"
      Properties:
        BucketName: ${self:provider.environment.RECORDS_BUCKET_NAME2}
    S3ComprehendBucket:
      Type: "AWS::S3::Bucket"
      Properties:
        BucketName: ${self:provider.environment.COMPREHEND_BUCKET_NAME}
